<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>torry&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.torry.top/"/>
  <updated>2017-11-30T13:38:37.250Z</updated>
  <id>http://www.torry.top/</id>
  
  <author>
    <name>torry</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关系型数据到非关系数据(MongoDB)转换经验总结</title>
    <link href="http://www.torry.top/2017/11/19/data-convert/"/>
    <id>http://www.torry.top/2017/11/19/data-convert/</id>
    <published>2017-11-18T16:00:00.000Z</published>
    <updated>2017-11-30T13:38:37.250Z</updated>
    
    <content type="html"><![CDATA[<p>系统微服务化后不可避免的面临数据碎片问题，大量数据分散存放在不同数据库中。单库环境下的关联查询基本无法满足纷繁复杂的业务需求。数据归集处理是解决以上问题的可靠方案之一。MongoDB出色的查询性能和高实时性以及简单易用的特性使之成为数据归集的目标数据库最佳之选。<br><a id="more"></a></p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>先来比较关系型数据库和MongoDB的优缺点：</p><p>MongoDB的优势：</p><ul><li>mongodb是面向文档存储，存储格式类似JSON,数据操作起来比较简单和容易</li><li>热数据存放内存，查询效率非常高</li><li>数据之间没有耦合性，所以非常容易水平扩展。自带shard功能</li><li>支持MapReduce，聚合操作性能很高</li></ul><p>关系型数据库的优势：</p><ul><li>复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。</li><li>事务支持使得对于安全性能很高的数据访问要求得以实现。</li></ul><p>对于这两类数据库，对方的优势就是自己的弱势，反之亦然。</p><p>一句话总结：mongodb满足性能需求，但不支持关联查询</p><p>既然无法直接做多维度数据查询，那就需要对数据进行处理，以满足多维度查询需要。</p><h2 id="转换方法"><a href="#转换方法" class="headerlink" title="转换方法"></a>转换方法</h2><h4 id="模拟案例："><a href="#模拟案例：" class="headerlink" title="模拟案例："></a>模拟案例：</h4><p>关系数据：</p><pre><code>用户数据：user_info(id,userNo,username,realname,accountNo,age)user_other_info(id,userNo,otherInfo)账户数据：account_info(id,accountNo,userNo,balance,frozenAmount)订单数据order_info(id,orderNo,userNo,price,payAmount)</code></pre><h4 id="关联方法"><a href="#关联方法" class="headerlink" title="关联方法"></a>关联方法</h4><ol><li>冗余字段关联</li></ol><p>如果一个数据查询需求需要查询的维度并不多，可以直接在原数据基础上拼接关联字段组成新的文档，以满足需求。比如账户数据除账户属性外还需要根据账户所属用户(username)的名称查询，账户数据转化如下：</p><pre><code>account(id,accountNo,userNo,balance,frozenAmount，username)</code></pre><p>此种方式优点是：数据冗余比较少，数据占用空间小，存储成本较低；缺点也很明显，当数据需求变化比较多的时候，无法兼容更多需求，比如产品经理说：加个需求，按用户真实姓名(realname)查询</p><ol><li>多合一关联</li></ol><p>如果业务表水平扩展比较多，比如用户信息会根据业务分成多张一对一数据表，这样可以将不同业务的表最为子文档，按唯一标识(userNo)组合拼接到一个文档中，比如用户信息转换如下：</p><pre><code>user(    userNo,    userInfo(id,userNo,username,realname,accountNo,age),    userOtherInfo(id,userNo,otherInfo)    )</code></pre><p>以上方式优点是业务兼容性强，数据扩展修改方便，就算是实时同步的数据乱序插入时，也能根据唯一索引可以归集到一个文档中。缺点是数据冗余较多，存储成本较高</p><ol><li>一合多关联</li></ol><p>当数据生成时，关联一些已有数据时，可以在原数据的基础上直接扩展子文档，比如订单数据转换如下：</p><pre><code>order(id,orderNo,userNo,price,payAmount,    userInfo(id,userNo,username,realname,accountNo,age),    userOtherInfo(id,userNo,otherInfo)    )</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>所有的数据转换都是给予现有数据模型来做的，做关系数据模型设计时一定要规范化</li><li>所有的数据转换都是为了满足业务需求来的，所以在做数据转换时，一定要先对业务需求有一定了解</li><li>在满足需求的情况下，可以尽量减少数据关联，避免存储浪费并提高性能。在有该数据维度查询需求时才加数据关联</li></ul><p><strong><em>tip:</em></strong><br>以上总结是我基于mysql到mongoDB同步完数据做数据关联时总结出来的部分经验，当做非关系型数据到mongoDB做数据关联时可以根据不同数据模型和需求选择合适的转化方法。所用数据同步方案：<a href="http://www.torry.top/2017/10/22/canal-mongodb">http://www.torry.top/2017/10/22/canal-mongodb</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;系统微服务化后不可避免的面临数据碎片问题，大量数据分散存放在不同数据库中。单库环境下的关联查询基本无法满足纷繁复杂的业务需求。数据归集处理是解决以上问题的可靠方案之一。MongoDB出色的查询性能和高实时性以及简单易用的特性使之成为数据归集的目标数据库最佳之选。&lt;br&gt;
    
    </summary>
    
    
      <category term="mysql" scheme="http://www.torry.top/tags/mysql/"/>
    
      <category term="mongodb" scheme="http://www.torry.top/tags/mongodb/"/>
    
      <category term="总结" scheme="http://www.torry.top/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>微服务MySQL分库分表数据到MongoDB同步方案</title>
    <link href="http://www.torry.top/2017/10/22/canal-mongodb/"/>
    <id>http://www.torry.top/2017/10/22/canal-mongodb/</id>
    <published>2017-10-21T16:00:00.000Z</published>
    <updated>2017-11-30T13:38:23.794Z</updated>
    
    <content type="html"><![CDATA[<p>  近年来，微服务概念持续火热，网络上针对微服务和单体架构的讨论也是越来越多，面对日益增长的业务需求是，很多公司做技术架构升级时优先选用微服务方式。我所在公司也是选的这个方向来升级技术架构，以支撑更大访问量和更方便的业务扩展。<br><a id="more"></a></p><h2 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h2><p>  微服务拆分主要分两种方式：拆分业务系统不拆分数据库，拆分业务系统拆分库。如果数据规模小的话大可不必拆分数据库，因为拆分数据看必将面对多维度数据查询，跨进程之间的事务等问题。而我所在公司随着业务发展单数据库实例已经不能满足业务需要，所以选择了拆分业务系统同时拆分数据库的模式，所以也面临着以上的问题。本文主要介绍多维度数据实时查询解决方案。当前系统架构和存储结构如下：</p><p>   <img src="http://www.torry.top/images//micro_mysql.png" alt="image"></p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><ul><li>要对多数据库数据进行查询，首先就需要将数据库同步到一起以方便查询</li><li>为了满足大数据量数据需求，所以优先选择NOSQL数据库做同步库</li><li>NOSQL数据库基本无法进行关联查询，所以需要将关系数据进行拼接操作，转换成非关系型数据</li><li>业务多维度查询需要实时性，所以需要选择NOSQL中实时性相对比较好的数据库：MongoDB</li></ul><p>根据以上思路，总结数据整合架构如下图所示：</p><p> <img src="http://www.torry.top/images/mysql-mongo.png" alt="image"></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>目前网上一些数据同步案例分两种：MQ消息同步和binlog数据读取同步</p><p>先说MQ消息同步，该同步方式我所在公司试用过一段时间，发现以下问题：</p><ul><li>数据围绕业务进行，对业务关键性数据操作发送MQ消息，对业务系统依赖性比较高</li><li>对于数据库中存量数据需要单独处理</li><li>对于工具表还需要单独维护同步</li><li>每次新增数据表都需要重新添加MQ逻辑</li></ul><p>考虑到以上问题，用MQ方式同步数据并不是最优解决办法</p><p>使用binlog 数据读取方式目前有一些成熟方案，比如tungsten replicator，但这些同步工具只能实现数据1:1复制，数据复制过程自定义逻辑添加比较麻烦，不支持分库分表数据归集操作。综上所述，最优方案应该是读取后binlog后自行处理后续数据逻辑。目前binlog读取binlog工具中最成熟的方案应该就是alibaba开源的canal了。</p><h4 id="canal"><a href="#canal" class="headerlink" title="canal"></a>canal</h4><p>canal是阿里巴巴mysql数据库binlog的增量订阅&amp;消费组件 。阿里云DRDS、阿里巴巴TDDL 二级索引、小表复制. 都是基于canal做的，应用广泛。<br>canal原理相对比较简单：</p><ul><li>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</li><li>mysql master收到dump请求，开始推送binary log给slave(也就是canal)</li><li>canal解析binary log对象(原始为byte流)</li></ul><p>canal介绍： <a href="https://github.com/alibaba/canal/wiki" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki</a></p><p>我使用的是canal的HA模式,由zookeeper选举可用实例，每个数据库一个instance,服务端配置如下：</p><p>目录：</p><pre><code>conf    database1        -instance.properties    database2        -instance.properties    canal.properties</code></pre><p>instance.properties</p><pre><code>canal.instance.mysql.slaveId = 1001canal.instance.master.address = X.X.X.X:3306canal.instance.master.journal.name = canal.instance.master.position = canal.instance.master.timestamp = canal.instance.dbUsername = canalcanal.instance.dbPassword = canalcanal.instance.defaultDatabaseName =canal.instance.connectionCharset = UTF-8canal.instance.filter.regex = .*\\..*canal.instance.filter.black.regex =  </code></pre><p>canal.properties</p><pre><code>canal.id= 1canal.ip=X.X.X.Xcanal.port= 11111canal.zkServers=X.X.X.X:2181,X.X.X.X:2181,X.X.X.X:2181canal.zookeeper.flush.period = 1000canal.file.data.dir = ${canal.conf.dir}canal.file.flush.period = 1000canal.instance.memory.buffer.size = 16384canal.instance.memory.buffer.memunit = 1024 canal.instance.memory.batch.mode = MEMSIZEcanal.instance.detecting.enable = truecanal.instance.detecting.sql = select 1canal.instance.detecting.interval.time = 3canal.instance.detecting.retry.threshold = 3canal.instance.detecting.heartbeatHaEnable = falsecanal.instance.transaction.size =  1024canal.instance.fallbackIntervalInSeconds = 60canal.instance.network.receiveBufferSize = 16384canal.instance.network.sendBufferSize = 16384canal.instance.network.soTimeout = 30canal.instance.filter.query.dcl = truecanal.instance.filter.query.dml = falsecanal.instance.filter.query.ddl = falsecanal.instance.filter.table.error = falsecanal.instance.filter.rows = falsecanal.instance.binlog.format = ROW,STATEMENT,MIXED canal.instance.binlog.image = FULL,MINIMAL,NOBLOBcanal.instance.get.ddl.isolation = falsecanal.destinations= example,p4-testcanal.conf.dir = ../confcanal.auto.scan = truecanal.auto.scan.interval = 5canal.instance.global.mode = spring canal.instance.global.lazy = falsecanal.instance.global.spring.xml = classpath:spring/default-instance.xml</code></pre><p>部署数据流如下：</p><p> <img src="http://www.torry.top/images/canal-deploy.png" alt="image"></p><p><strong><em>tip:</em></strong><br><em>虽然canal同时支持mixed和row类型的binlog日志，但是获取行数据时如果是mixed类型的日志则获取不到表名，所以本方案暂只支持row格式的binlog</em></p><h4 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h4><p>创建canal client应用订阅canal读取的binlog数据</p><p>1.开启多instance 订阅,订阅多个instance</p><blockquote><pre><code>public void initCanalStart() {    List&lt;String&gt; destinations = canalProperties.getDestination();    final List&lt;CanalClient&gt; canalClientList = new ArrayList&lt;&gt;();    if (destinations != null &amp;&amp; destinations.size() &gt; 0) {        for (String destination : destinations) {            // 基于zookeeper动态获取canal server的地址，建立链接，其中一台server发生crash，可以支持failover            CanalConnector connector = CanalConnectors.newClusterConnector(canalProperties.getZkServers(), destination, &quot;&quot;, &quot;&quot;);            CanalClient client = new CanalClient(destination, connector);            canalClientList.add(client);            client.start();        }    }    Runtime.getRuntime().addShutdownHook(new Thread() {        public void run() {            try {                logger.info(&quot;## stop the canal client&quot;);                for (CanalClient canalClient : canalClientList) {                    canalClient.stop();                }            } catch (Throwable e) {                logger.warn(&quot;##something goes wrong when stopping canal:&quot;, e);            } finally {                logger.info(&quot;## canal client is down.&quot;);            }        }    });}</code></pre></blockquote><p>订阅消息处理</p><blockquote><pre><code>private void process() {    int batchSize = 5 * 1024;    while (running) {        try {            MDC.put(&quot;destination&quot;, destination);            connector.connect();            connector.subscribe();            while (running) {                Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据                long batchId = message.getId();                int size = message.getEntries().size();                if (batchId != -1 &amp;&amp; size &gt; 0) {                    saveEntry(message.getEntries());                }                connector.ack(batchId); // 提交确认                // connector.rollback(batchId); // 处理失败, 回滚数据            }        } catch (Exception e) {            logger.error(&quot;process error!&quot;, e);        } finally {            connector.disconnect();            MDC.remove(&quot;destination&quot;);        }    }}</code></pre></blockquote><p>根据数据库事件处理消息,过滤消息列表，对数据变动进行处理,用到信息为：</p><ul><li>insert :schemaName,tableName,beforeColumnsList</li><li>update :schemaName,tableName,afterColumnsList</li><li>delete :schemaName,tableName,afterColumnsList</li></ul><blockquote><pre><code>RowChange rowChage = null;    try {        rowChage = RowChange.parseFrom(entry.getStoreValue());    } catch (Exception e) {        throw new RuntimeException(&quot;parse event has an error , data:&quot; + entry.toString(), e);    }    EventType eventType = rowChage.getEventType();    logger.info(row_format,            entry.getHeader().getLogfileName(),            String.valueOf(entry.getHeader().getLogfileOffset()), entry.getHeader().getSchemaName(),            entry.getHeader().getTableName(), eventType,            String.valueOf(entry.getHeader().getExecuteTime()), String.valueOf(delayTime));    if (eventType == EventType.QUERY || rowChage.getIsDdl()) {        logger.info(&quot; sql ----&gt; &quot; + rowChage.getSql());        continue;    }    DataService dataService = SpringUtil.getBean(DataService.class);    for (RowData rowData : rowChage.getRowDatasList()) {        if (eventType == EventType.DELETE) {            dataService.delete(rowData.getBeforeColumnsList(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName());        } else if (eventType == EventType.INSERT) {            dataService.insert(rowData.getAfterColumnsList(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName());        } else if (eventType == EventType.UPDATE) {            dataService.update(rowData.getAfterColumnsList(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName());        } else {            logger.info(&quot;未知数据变动类型：{}&quot;, eventType);        }    }}</code></pre></blockquote><p>ColumnsList转换成MongoTemplate 可用的数据类：DBObject,顺便做下数据类型转换</p><blockquote><pre><code>public static DBObject columnToJson(List&lt;CanalEntry.Column&gt; columns) {    DBObject obj = new BasicDBObject();    try {        for (CanalEntry.Column column : columns) {            String mysqlType = column.getMysqlType();            //int类型，长度11以下为Integer，以上为long            if (mysqlType.startsWith(&quot;int&quot;)) {                int lenBegin = mysqlType.indexOf(&apos;(&apos;);                int lenEnd = mysqlType.indexOf(&apos;)&apos;);                if (lenBegin &gt; 0 &amp;&amp; lenEnd &gt; 0) {                    int length = Integer.parseInt(mysqlType.substring(lenBegin + 1, lenEnd));                    if (length &gt; 10) {                        obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : Long.parseLong(column.getValue()));                        continue;                    }                }                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : Integer.parseInt(column.getValue()));            } else if (mysqlType.startsWith(&quot;bigint&quot;)) {                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : Long.parseLong(column.getValue()));            } else if (mysqlType.startsWith(&quot;decimal&quot;)) {                int lenBegin = mysqlType.indexOf(&apos;(&apos;);                int lenCenter = mysqlType.indexOf(&apos;,&apos;);                int lenEnd = mysqlType.indexOf(&apos;)&apos;);                if (lenBegin &gt; 0 &amp;&amp; lenEnd &gt; 0 &amp;&amp; lenCenter &gt; 0) {                    int length = Integer.parseInt(mysqlType.substring(lenCenter + 1, lenEnd));                    if (length == 0) {                        obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : Long.parseLong(column.getValue()));                        continue;                    }                }                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : Double.parseDouble(column.getValue()));            } else if (mysqlType.equals(&quot;datetime&quot;) || mysqlType.equals(&quot;timestamp&quot;)) {                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : DATE_TIME_FORMAT.parse(column.getValue()));            } else if (mysqlType.equals(&quot;date&quot;)) {                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : DATE_FORMAT.parse(column.getValue()));            } else if (mysqlType.equals(&quot;time&quot;)) {                obj.put(column.getName(), StringUtils.isBlank(column.getValue()) ? null : TIME_FORMAT.parse(column.getValue()));            } else {                obj.put(column.getName(), column.getValue());            }        }    } catch (ParseException e) {        e.printStackTrace();    }    return obj;}</code></pre></blockquote><p><strong><em>tip:</em></strong><br><em>DBObject对象如果同时用于保存原始数据和组合数据或其他数据，使用时应该深度拷贝对象生成副本，然后使用副本</em></p><h4 id="数据拼接"><a href="#数据拼接" class="headerlink" title="数据拼接"></a>数据拼接</h4><p>我们获取了数据库数据后做拼接操作，比如两张用户表：</p><pre><code>user_info:{id,user_no,user_name,user_password}user_other_info:{id,user_no,idcard,realname}</code></pre><p>拼接后mongo数据为：</p><pre><code>user:{_id,user_no,userInfo:{id,user_no,user_name,user_password},userOtherInfo:{id,user_no,idcard,realname})</code></pre><p>接收到的数据信息很多，如何才能简单的触发数据拼接操作呢？</p><p>先看我们能获取的信息:schemaName,tableName,DBObject,Event(insert,update,delete)</p><p>将这些信息标识拼接起来看看:/schemaName/tableName/Event(DBObject),没错,就是一个标准的restful链接。只要我们实现一个简单的springMVC 就能自动获取需要的数据信息进行拼接操作。</p><p>先实现@Controller,定义名称为Schema，value对应schemaName</p><blockquote><pre><code>@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic  @interface Schema { String value() default &quot;&quot;;}</code></pre></blockquote><p>然后实现@RequestMapping,定义名称为Table,直接使用Canal中的EventType 对应RequestMethod</p><blockquote><pre><code>@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic  @interface Table {    String value() default &quot;&quot;;    CanalEntry.EventType[] event() default {};}</code></pre></blockquote><p>然后创建springUtil,实现接口ApplicationContextAware，应用启动 加载的时候初始化两个Map:intanceMap,handlerMap</p><blockquote><pre><code>private static ApplicationContext applicationContext = null;//库名和数据处理Bean映射Mapprivate static Map&lt;String, Object&gt; instanceMap = new HashMap&lt;String, Object&gt;();//路劲和数据处理Method映射Mapprivate static Map&lt;String, Method&gt; handlerMap = new HashMap&lt;String, Method&gt;();@Overridepublic void setApplicationContext(ApplicationContext applicationContext) {    if (SpringUtil.applicationContext == null) {        SpringUtil.applicationContext = applicationContext;        //初始化instanceMap数据        instanceMap();        //初始化handlerMap数据        handlerMap();    }}private void instanceMap() {    Map&lt;String, Object&gt; beans = applicationContext.getBeansWithAnnotation(Schema.class);    for (Object bean : beans.values()) {        Class&lt;?&gt; clazz = bean.getClass();        Object instance = applicationContext.getBean(clazz);        Schema schema = clazz.getAnnotation(Schema.class);        String key = schema.value();        instanceMap.put(key, instance);        logger.info(&quot;instanceMap [{}:{}]&quot;, key, bean == null ? &quot;null&quot; : clazz.getName());    }}private void handlerMap() {    if (instanceMap.size() &lt;= 0)        return;    for (Map.Entry&lt;String, Object&gt; entry : instanceMap.entrySet()) {        if (entry.getValue().getClass().isAnnotationPresent(Schema.class)) {            Schema schema = entry.getValue().getClass().getAnnotation(Schema.class);            String schemeName = schema.value();            Method[] methods = entry.getValue().getClass().getMethods();            for (Method method : methods) {                if (method.isAnnotationPresent(Table.class)) {                    Table table = method.getAnnotation(Table.class);                    String tName = table.value();                    CanalEntry.EventType[] events = table.event();                    //未标明数据事件类型的方法不做映射                    if (events.length &lt; 1) {                        continue;                    }                    //同一个方法可以映射多张表                    for (int i = 0; i &lt; events.length; i++) {                        String path = &quot;/&quot; + schemeName + &quot;/&quot; + tName + &quot;/&quot; + events[i].getNumber();                        handlerMap.put(path, method);                        logger.info(&quot;handlerMap [{}:{}]&quot;, path, method.getName());                    }                } else {                    continue;                }            }        } else {            continue;        }    }}</code></pre></blockquote><p>调用方法：</p><blockquote><pre><code>public static void doEvent(String path, DBObject obj) throws Exception {    String[] pathArray = path.split(&quot;/&quot;);    if (pathArray.length != 4) {        logger.info(&quot;path 格式不正确：{}&quot;, path);        return;    }    Method method = handlerMap.get(path);    Object schema = instanceMap.get(pathArray[1]);    //查找不到映射Bean和Method不做处理    if (method == null || schema == null) {        return;    }    try {        long begin = System.currentTimeMillis();        logger.info(&quot;integrate data：{}，{}&quot;, path, obj);        method.invoke(schema, new Object[]{obj});        logger.info(&quot;integrate data consume: {}ms：&quot;, System.currentTimeMillis() - begin);    } catch (Exception e) {        logger.error(&quot;调用组合逻辑异常&quot;, e);        throw new Exception(e.getCause());    }}</code></pre></blockquote><p>数据拼接消息处理：</p><blockquote><pre><code>@Schema(&quot;demo_user&quot;)public class UserService {    @Table(value = &quot;user_info&quot;, event = {CanalEntry.EventType.INSERT, CanalEntry.EventType.UPDATE})    public void saveUser_UserInfo(DBObject userInfo) {        String userNo = userInfo.get(&quot;user_no&quot;) == null ? null : userInfo.get(&quot;user_no&quot;).toString();        DBCollection collection = completeMongoTemplate.getCollection(&quot;user&quot;);        DBObject queryObject = new BasicDBObject(&quot;user_no&quot;, userNo);        DBObject user = collection.findOne(queryObject);        if (user == null) {            user = new BasicDBObject();            user.put(&quot;user_no&quot;, userNo);            user.put(&quot;userInfo&quot;, userInfo);            collection.insert(user);        } else {            DBObject updateObj = new BasicDBObject(&quot;userInfo&quot;, userInfo);            DBObject update = new BasicDBObject(&quot;$set&quot;, updateObj);            collection.update(queryObject, update);        }    }}</code></pre></blockquote><h2 id="示例源码"><a href="#示例源码" class="headerlink" title="示例源码"></a>示例源码</h2><p><a href="https://github.com/zhangtr/canal-mongo" target="_blank" rel="noopener">https://github.com/zhangtr/canal-mongo</a></p><p>欢迎讨论方案或者指正代码</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  近年来，微服务概念持续火热，网络上针对微服务和单体架构的讨论也是越来越多，面对日益增长的业务需求是，很多公司做技术架构升级时优先选用微服务方式。我所在公司也是选的这个方向来升级技术架构，以支撑更大访问量和更方便的业务扩展。&lt;br&gt;
    
    </summary>
    
    
      <category term="mysql" scheme="http://www.torry.top/tags/mysql/"/>
    
      <category term="mongodb" scheme="http://www.torry.top/tags/mongodb/"/>
    
      <category term="canal" scheme="http://www.torry.top/tags/canal/"/>
    
  </entry>
  
  <entry>
    <title>权限管理平台teedao-rbac介绍</title>
    <link href="http://www.torry.top/2017/07/15/teedao-rbac-about/"/>
    <id>http://www.torry.top/2017/07/15/teedao-rbac-about/</id>
    <published>2017-07-14T16:00:00.000Z</published>
    <updated>2017-11-30T13:38:53.865Z</updated>
    
    <content type="html"><![CDATA[<p>  随着业务的发展，很多公司都需要上线多个不同业务的后台运营平台，如后台管理，销售业务系to统，财务系统等。如果每个系统都单独开发一个用户模块，会造成用户数据冗余，运营操作繁琐，开发工作重复等问题，所以需要一套统一用户管理方案来解决这些问题:teedao-rbac<br>  <a id="more"></a></p><h2 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h2><ul><li>metronic ui模板</li><li>thymeleaf 页面模板</li><li>springboot 容器框架</li><li>oauth2 授权登录协议</li><li>shiro 权限管理框架</li><li>mybatis orm框架</li><li>druid 数据库连接池</li></ul><h2 id="OAuth2介绍"><a href="#OAuth2介绍" class="headerlink" title="OAuth2介绍"></a>OAuth2介绍</h2><h4 id="OAuth角色"><a href="#OAuth角色" class="headerlink" title="OAuth角色"></a>OAuth角色</h4><p>资源拥有者（resource owner）：能授权访问受保护资源的一个实体，可以是一个人，那我们称之为最终用户；如新浪微博用户zhangsan；</p><p>资源服务器（resource server）：存储受保护资源，客户端通过access token请求资源，资源服务器响应受保护资源给客户端；存储着用户zhangsan的微博等信息。</p><p>授权服务器（authorization server）：成功验证资源拥有者并获取授权之后，授权服务器颁发授权令牌（Access Token）给客户端。</p><p>客户端（client）：如新浪微博客户端weico、微格等第三方应用，也可以是它自己的官方应用；其本身不存储资源，而是资源拥有者授权通过后，使用它的授权（授权令牌）访问受保护资源，然后客户端把相应的数据展示出来/提交到服务器。“客户端”术语不代表任何特定实现（如应用运行在一台服务器、桌面、手机或其他设备）。<br><img src="http://ot0uzdjr7.bkt.clouddn.com/oauth2-uml.png" alt="image"></p><ol><li>客户端从资源拥有者那请求授权。授权请求可以直接发给资源拥有者，或间接的通过授权服务器这种中介，后者更可取。</li><li>客户端收到一个授权许可，代表资源服务器提供的授权。</li><li>客户端使用它自己的私有证书及授权许可到授权服务器验证。</li><li>如果验证成功，则下发一个访问令牌。</li><li>客户端使用访问令牌向资源服务器请求受保护资源。</li><li>资源服务器会验证访问令牌的有效性，如果成功则下发受保护资源</li></ol><h2 id="Apache-Shiro介绍"><a href="#Apache-Shiro介绍" class="headerlink" title="Apache Shiro介绍"></a>Apache Shiro介绍</h2><p>Shiro是一个功能强大且接口简单的安全控制框架，其不仅可以用在JavaSE环境，也可以用在JavaEE环境。Shiro可以帮助我们完成：认证、授权、加密、会话管理、与Web集成、缓存等。其基本功能点如下图所示：<br><img src="http://ot0uzdjr7.bkt.clouddn.com/ShiroFeatures.png" alt="image"></p><ul><li>Authentication：身份认证/登录，验证用户是不是拥有相应的身份；</li><li>Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限；</li><li>Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的；</li><li>Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储；</li><li>Web Support：Web支持，可以非常容易的集成到Web环境；</li><li>Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率；</li><li>Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；</li><li>Testing：提供测试支持；</li><li>Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；</li><li>Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。</li></ul><blockquote><p>记住一点，Shiro不会去维护用户、维护权限；这些需要我们自己去设计/提供；然后通过相应的接口注入给Shiro即可。</p></blockquote><p> 接下来我们分别从外部和内部来看看Shiro的架构，对于一个好的框架，从外部来看应该具有非常简单易于使用的API，且API契约明确；从内部来看的话，其应该有一个可扩展的架构，即非常容易插入用户自定义实现，因为任何框架都不能满足所有需求。</p><p>首先，我们从外部来看Shiro吧，即从应用程序角度的来观察如何使用Shiro完成工作。如下图：</p><p><img src="http://ot0uzdjr7.bkt.clouddn.com/shiro-flow.png" alt="image"></p><p>可以看到：应用代码直接交互的对象是Subject，也就是说Shiro的对外API核心就是Subject；其每个API的含义：</p><ul><li>Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是Subject，如网络爬虫，机器人等；即一个抽象概念；所有Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager；可以把Subject认为是一个门面；SecurityManager才是实际的执行者；</li><li>SecurityManager：安全管理器；即所有与安全有关的操作都会与SecurityManager交互；且它管理着所有Subject；可以看出它是Shiro的核心，它负责与后边介绍的其他组件进行交互，如果学习过SpringMVC，你可以把它看成DispatcherServlet前端控制器；</li><li>Realm：域，Shiro从从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。</li></ul><p>也就是说对于我们而言，最简单的一个Shiro应用：</p><ol><li>应用代码通过Subject来进行认证和授权，而Subject又委托给SecurityManager；</li><li>我们需要给Shiro的SecurityManager注入Realm，从而让SecurityManager能得到合法的用户及其权限进行判断。</li></ol><p>从以上也可以看出，Shiro不提供维护用户/权限，而是通过Realm让开发人员自己注入。</p><p>接下来我们来从Shiro内部来看下Shiro的架构，如下图所示：</p><p><img src="http://ot0uzdjr7.bkt.clouddn.com/shiro-framework.png" alt="image"></p><ul><li>Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”；</li><li>SecurityManager：相当于SpringMVC中的DispatcherServlet或者Struts2中的FilterDispatcher；是Shiro的心脏；所有具体的交互都通过SecurityManager进行控制；它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理。</li><li>Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得Shiro默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了；</li><li>Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能；</li><li>Realm：可以有1个或多个Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm；</li><li>SessionManager：如果写过Servlet就应该知道Session的概念，Session呢需要有人去管理它的生命周期，这个组件就是SessionManager；而Shiro并不仅仅可以用在Web环境，也可以用在如普通的JavaSE环境、EJB等环境；所有呢，Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据；这样的话，比如我们在Web环境用，刚开始是一台Web服务器；接着又上了台EJB服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到Memcached服务器）；</li><li>SessionDAO：DAO大家都用过，数据访问对象，用于会话的CRUD，比如我们想把Session保存到数据库，那么可以实现自己的SessionDAO，通过如JDBC写到数据库；比如想把Session放到Memcached中，可以实现自己的Memcached SessionDAO；另外SessionDAO中可以使用Cache进行缓存，以提高性能；</li><li>CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能</li><li>Cryptography：密码模块，Shiro提高了一些常见的加密组件用于如密码加密/解密的。</li></ul><h2 id="teedao-rbac登录流程"><a href="#teedao-rbac登录流程" class="headerlink" title="teedao-rbac登录流程"></a>teedao-rbac登录流程</h2><p><img src="http://ot0uzdjr7.bkt.clouddn.com/login-uml.png" alt="image"></p><ol><li>用户访问客户端系统</li><li>客户端系统发送授权请求，获取accessToken，重定向到teedao-rbac</li><li>teedao-rbac 返回登录页面</li><li>用户填写用户名密码提交登录</li><li>用户登录成功，teedao-rbac重定向到客户端系统</li><li>客户端系统根据accessToken 请求用户资源</li><li>teedao-rabc 返回用户信息及客户端权限信息</li><li>客户端系统根据用户信息及权限信息渲染用户页面<h2 id="权限模型"><a href="#权限模型" class="headerlink" title="权限模型"></a>权限模型</h2>用户权限基于用户-角色-资源的基本权限模型，加入站点属性，用以支持多站点权限管理<br>数据库模型如下：<br><img src="http://ot0uzdjr7.bkt.clouddn.com/teedao-eer.png" alt="image"></li></ol><h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p><a href="https://github.com/zhangtr/teedao" target="_blank" rel="noopener">https://github.com/zhangtr/teedao</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://jinnianshilongnian.iteye.com/blog/2018398" target="_blank" rel="noopener">开涛的博客-跟我学shiro</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  随着业务的发展，很多公司都需要上线多个不同业务的后台运营平台，如后台管理，销售业务系to统，财务系统等。如果每个系统都单独开发一个用户模块，会造成用户数据冗余，运营操作繁琐，开发工作重复等问题，所以需要一套统一用户管理方案来解决这些问题:teedao-rbac&lt;br&gt;
    
    </summary>
    
    
      <category term="teedao" scheme="http://www.torry.top/tags/teedao/"/>
    
      <category term="springboot" scheme="http://www.torry.top/tags/springboot/"/>
    
      <category term="oauth2" scheme="http://www.torry.top/tags/oauth2/"/>
    
      <category term="shiro" scheme="http://www.torry.top/tags/shiro/"/>
    
      <category term="rbac" scheme="http://www.torry.top/tags/rbac/"/>
    
  </entry>
  
</feed>
